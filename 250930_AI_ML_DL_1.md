
### 파트 1: AI 가상 환경 만들기 (Anaconda + PyTorch + PyCharm)
https://www.anaconda.com/download
윈도우 검색창 -> anaconda prompt (우클릭 , 관리자 실행)
conda create -n Pytorch python=3.10 가상환경
conda env list 콘다 리스트 , 목록 조회 
conda activate Pytorch 콘다 실행, 활성화 하기. 
gpu , -> nvidia 기준으로, cuda 관련 라이브러리 설치. cuda 12.x, 각자 
그래픽 카드에 맞게 설치.(현재, 생략)

https://pytorch.org/get-started/locally/
1 Stable 2.8.0 -> 2 Windows -> 3 Pip -> 4 CPU 
선택 후 결과 설치 명령어
pip3 install torch torchvision
---

#### **1단계: Anaconda 가상 환경 생성**

1.  **Anaconda Prompt 실행**: Windows 검색창에서 'Anaconda Prompt'를 찾아 실행합니다. (macOS나 Linux에서는 터미널을 실행합니다.)

2.  **가상 환경 생성**: 다음 명령어를 입력하여 'ai_env'라는 이름의 새로운 가상 환경을 만듭니다. Python 버전은 3.11과 같이 안정적인 최신 버전을 지정하는 것이 좋습니다.

    ```bash
    conda create -n ai_env python=3.10
    ```
    *   `ai_env`는 원하는 가상 환경의 이름으로 자유롭게 변경할 수 있습니다.
    *   설치 과정에서 진행 여부를 묻는 메시지(`Proceed ([y]/n)?`)가 나오면 `y`를 입력하고 엔터를 누릅니다.

3.  **가상 환경 활성화**: 생성한 가상 환경에 들어가기 위해 아래 명령어를 실행합니다.

    ```bash
    conda activate ai_env
    ```
    *   명령어 앞부분이 `(base)`에서 `(ai_env)`로 바뀌면 가상 환경이 성공적으로 활성화된 것입니다.

---

#### **2단계: PyTorch 설치**

활성화된 `ai_env` 가상 환경 안에 AI 개발의 핵심 라이브러리인 PyTorch를 설치합니다.

1.  **PyTorch 공식 홈페이지 방문**: [PyTorch 공식 홈페이지](https://pytorch.org/)에 접속하여 자신의 환경에 맞는 설치 명령어를 확인하는 것이 가장 정확합니다.

2.  **설치 명령어 실행**: 일반적으로 다음 명령어를 사용하여 안정적인 최신 버전의 PyTorch를 설치할 수 있습니다 (CUDA 사용 가능 환경 기준).

    ```bash
    conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
    ```    *   만약 그래픽카드(GPU)가 없거나 NVIDIA 그래픽카드가 아니라면 CPU 버전을 설치해야 합니다. 공식 홈페이지에서 'Compute Platform'을 'CPU'로 선택하고 생성된 명령어를 사용하세요.

---

#### **3단계: PyCharm과 Anaconda 가상 환경 연동**
파이참 프로에서, 콘다 가상환경 설정. 
파일 -> 설정, -> 프로젝트 ~ -> 파이썬 인터 프리터 
-> 콘다 가상화 이름  Pytorch 보이면 정상이고, 선택.
-> 만약, 안보인다. -> 인터프리터 추가 -> 로컬 -> 기존 항목 
-> 콘다 부분에 , 해당 Pytorch 이름이 있다. 선택. 

이제 코드를 작성하고 실행할 통합 개발 환경(IDE)인 PyCharm에서 우리가 만든 가상 환경을 사용하도록 설정해야 합니다.

1.  **PyCharm에서 새 프로젝트 생성**: PyCharm을 실행하고 `New Project`를 클릭합니다.

2.  **Python Interpreter 설정**: 새 프로젝트 설정 화면에서 가장 중요한 부분은 **Python Interpreter**를 지정하는 것입니다.
    *   `New environment using` 옵션 대신 `Previously configured interpreter`를 선택합니다.
    *   오른쪽의 `...` 버튼을 클릭한 후, `Add Python Interpreter`를 선택합니다.
    *   왼쪽 탭에서 `Conda Environment`를 선택합니다.
    *   `Use existing environment`를 선택하고, Interpreter 목록에서 방금 생성한 `ai_env`를 찾아 선택합니다. (보통 Anaconda 설치 경로 내의 `envs/ai_env/python.exe`에 위치합니다.)
    *   `OK`를 눌러 설정을 완료하고 프로젝트를 생성합니다.

이제 PyCharm 프로젝트는 `ai_env`라는 격리된 환경에서 실행되며, 이 환경에 설치된 PyTorch를 자유롭게 사용할 수 있습니다.

### 파트 2: AI 개발을 위한 기초 개념 (PyTorch 핵심 기능)

환경 설정이 완료되었으니, 이제 AI 개발의 기초가 되는 PyTorch의 핵심 기능들을 알아보겠습니다.

---

#### **1. 텐서(Tensor): AI 모델의 기본 데이터 단위**

텐서(Tensor)는 PyTorch에서 모든 연산의 기본이 되는 핵심 데이터 구조입니다. 배열(array)이나 행렬(matrix)과 매우 유사하지만, GPU를 사용한 연산 가속이 가능하고 자동 미분 기능을 지원한다는 중요한 차이점이 있습니다. 모델의 입력과 출력, 그리고 모델 내부의 파라미터(가중치)들이 모두 텐서 형태로 표현됩니다.

**텐서 생성하기**

```python
import torch

# Python 리스트로부터 텐서 생성
data = [[1, 2], [3, 4]]
x_data = torch.tensor(data)
print(x_data)

# 텐서의 속성 확인
print(f"Shape of tensor: {x_data.shape}") # 모양(shape)
print(f"Datatype of tensor: {x_data.dtype}") # 자료형(datatype)
print(f"Device tensor is stored on: {x_data.device}") # 저장된 장치(cpu/gpu)
```

텐서는 GPU로 옮겨서 연산 속도를 크게 향상시킬 수 있습니다.

```python
# GPU가 사용 가능하다면 텐서를 GPU로 이동
if torch.cuda.is_available():
    x_data = x_data.to('cuda')
    print(f"Device tensor is stored on: {x_data.device}")
```

---

#### **2. Autograd: 자동 미분 기능**

PyTorch의 `autograd`는 신경망 학습의 핵심인 역전파(backpropagation)를 위한 자동 미분 기능을 제공합니다. 텐서에 대한 모든 연산을 추적하여, 어떤 텐서에 대해 `loss.backward()`가 호출되면 자동으로 모든 파라미터에 대한 그래디언트(gradient, 기울기)를 계산해줍니다. 이 그래디언트 값을 이용하여 모델의 가중치를 업데이트하고 모델을 학습시킵니다.

---

#### **3. `torch.nn.Module`: 신경망 모델 만들기**

PyTorch에서 모든 신경망 모델은 `torch.nn.Module` 클래스를 상속받아 만들어집니다. 모델을 만든다는 것은 크게 두 가지 과정을 포함합니다.

1.  `__init__()` (초기화 함수): 모델에 필요한 층(layer)들을 정의합니다. (예: 선형 계층, 활성화 함수 등)
2.  `forward()` 함수: 모델의 입력(텐서)을 받아 어떻게 계산을 수행하고 출력을 반환할지, 즉 데이터의 흐름을 정의합니다.

**간단한 신경망 모델 예시**

```python
import torch.nn as nn

class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        # 입력-중간-출력 층을 정의
        self.layer1 = nn.Linear(in_features=10, out_features=32)
        self.activation = nn.ReLU()
        self.layer2 = nn.Linear(in_features=32, out_features=1)

    def forward(self, x):
        # 데이터의 흐름을 정의
        x = self.layer1(x)
        x = self.activation(x)
        x = self.layer2(x)
        return x

# 모델 객체 생성
model = SimpleModel()
print(model)
```

---

#### **4. 데이터셋(Dataset)과 데이터로더(DataLoader)**

`Dataset`과 `DataLoader`는 모델에 데이터를 효율적으로 공급하기 위한 도구입니다.

*   **Dataset**: 샘플과 정답을 저장하는 객체입니다.
*   **DataLoader**: `Dataset`을 감싸서, 학습에 필요한 미니배치(mini-batch) 단위로 데이터를 쉽게 뽑아낼 수 있게 해주고 데이터를 섞는(shuffle) 등의 편의 기능을 제공합니다.

---

### 파트 2 심화: AI 개발을 위한 기초 개념 (PyTorch 핵심 기능)

CPU 환경에서 각 기능이 어떻게 동작하는지 코드를 직접 실행하며 익숙해지는 것이 중요합니다.

---

#### **1. 텐서(Tensor): 더욱 깊게 알아보기**

텐서는 단순히 데이터를 담는 그릇이 아니라, 다양한 형태와 연산을 통해 데이터를 자유자재로 다룰 수 있게 해주는 강력한 도구입니다.

*   **다양한 텐서 생성법:**
    ```python
    import torch

    # 특정 모양의 텐서를 0 또는 1로 채워서 생성
    shape = (2, 3) # 2행 3열
    zeros_tensor = torch.zeros(shape)
    ones_tensor = torch.ones(shape)

    # 특정 모양의 텐서를 무작위 값으로 채워서 생성
    # rand: 0과 1 사이의 균등 분포
    rand_tensor = torch.rand(shape)
    # randn: 평균 0, 표준편차 1의 정규 분포
    randn_tensor = torch.randn(shape)

    print(f"Zeros Tensor: \n {zeros_tensor} \n")
    print(f"Ones Tensor: \n {ones_tensor} \n")
    print(f"Random Tensor: \n {rand_tensor} \n")
    ```

*   **텐서의 연산(Operations):**
    텐서는 NumPy처럼 직관적인 연산을 지원합니다.
    ```python
    tensor = torch.ones(2, 2) # 2x2 크기의 1로 채워진 텐서
    
    # 텐서의 모든 요소에 10을 더함
    tensor_add = tensor.add(10)
    # 텐서의 모든 요소에 10을 곱함 (산술 연산자도 동일하게 동작)
    tensor_mul = tensor * 10

    print(f"덧셈 결과: \n {tensor_add} \n")
    print(f"곱셈 결과: \n {tensor_mul} \n")

    # 텐서 간의 연산 (행렬 곱)
    tensor2 = torch.tensor([[1, 2], [3, 4]])
    matrix_mul = tensor.matmul(tensor2) # 또는 tensor @ tensor2
    print(f"행렬 곱 결과: \n {matrix_mul} \n")
    ```

*   **인덱싱과 슬라이싱:**
    NumPy와 유사하게 특정 데이터를 추출할 수 있습니다.
    ```python
    tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
    
    print("첫 번째 행:", tensor[0])
    print("첫 번째 열:", tensor[:, 0])
    print("마지막 열:", tensor[..., -1])
    ```

---

#### **2. Autograd: 자동 미분 시스템의 작동 원리**

`autograd`는 "어떻게" 학습이 일어나는지에 대한 핵심입니다.

모델의 파라미터(가중치)는 학습을 통해 최적화되어야 할 값입니다. 텐서를 생성할 때 `requires_grad=True`로 설정하면, PyTorch는 이 텐서에 대한 모든 연산을 추적하는 연산 그래프(Computational Graph)를 만듭니다.

**예시:**
간단한 수식 `y = w * x + b` 에서 손실(loss)에 대한 `w`와 `b`의 기울기(gradient)를 구하는 과정입니다.

```python
# requires_grad=True : 이 텐서들에 대한 기울기를 계산하겠다고 명시
w = torch.randn(1, requires_grad=True)
b = torch.randn(1, requires_grad=True)
x = torch.tensor([2.0])
y_true = torch.tensor([10.0]) # 실제 정답

# 1. 순전파 (Forward Pass)
y_pred = w * x + b

# 2. 손실 계산 (Loss Calculation)
loss = (y_pred - y_true)**2

print(f"예측값: {y_pred.item()}, 손실: {loss.item()}")

# 3. 역전파 (Backward Pass)
# loss에 대한 모든 requires_grad=True 텐서의 기울기를 계산
loss.backward()

# 4. 기울기 확인
# 손실을 w로 미분한 값, 손실을 b로 미분한 값
print(f"w의 기울기(dL/dw): {w.grad.item()}")
print(f"b의 기울기(dL/db): {b.grad.item()}")
```
신경망 학습 시, 옵티마이저는 바로 이 `.grad`에 저장된 기울기 값을 사용하여 `w`와 `b`를 정답에 가까워지는 방향으로 조금씩 업데이트합니다.

---

#### **3. `torch.nn.Module`: 재사용 가능한 모델 설계**

`nn.Module`은 신경망의 계층(layer)들을 부품처럼 조립하여 모델이라는 하나의 제품을 만드는 설계도와 같습니다.

*   `__init__()`: 모델에 필요한 부품들(레이어)을 정의하는 곳입니다. `nn.Linear`, `nn.Conv2d`, `nn.ReLU` 등 PyTorch가 미리 만들어 둔 다양한 부품들을 가져와서 초기화합니다.
*   `forward()`: 데이터가 들어왔을 때, `__init__`에서 정의한 부품들을 어떤 순서로 통과시켜 최종 결과를 만들지 데이터의 흐름을 정의하는 곳입니다.

`forward()` 메소드를 직접 호출하지 않고 `model(input_data)`와 같이 객체 자체를 함수처럼 호출하면, PyTorch가 내부적으로 `forward()`를 실행하면서 추가적인 처리(hook 등)를 수행합니다. 따라서 항상 `model(input_data)` 형태로 사용해야 합니다.

---

### 파트 3: AI 모델 학습의 전체 과정

위의 기초 개념들을 조합하여 실제 모델을 학습시키는 과정은 다음과 같은 단계로 이루어집니다.

---

#### **5단계: 손실 함수(Loss Function)와 옵티마이저(Optimizer) 정의**

*   **손실 함수 (Loss Function)**: 모델의 예측이 실제 정답과 얼마나 다른지를 측정하는 함수입니다. 이 손실 값을 최소화하는 것이 학습의 목표입니다.
    *   **회귀 문제 (숫자 예측)**: `nn.MSELoss()` (평균 제곱 오차)
    *   **분류 문제 (카테고리 예측)**: `nn.CrossEntropyLoss()` (크로스 엔트로피)

*   **옵티마이저 (Optimizer)**: 손실 함수가 계산한 오차(기울기)를 바탕으로, 모델의 파라미터(가중치)를 어떤 방식과 어떤 강도(learning rate)로 업데이트할지 결정하는 알고리즘입니다.
    *   **`torch.optim.Adam`**: 가장 널리 사용되고 성능이 좋은 옵티마이저 중 하나로, 처음 시작할 때 좋은 선택입니다.
    *   **`torch.optim.SGD`**: 가장 기본적인 경사 하강법 옵티마이저입니다.

```python
# 이전에 정의한 SimpleModel을 사용한다고 가정
model = SimpleModel()

# 학습률(learning rate): 파라미터를 얼마나 크게 업데이트할지 결정
learning_rate = 0.01

# 손실 함수와 옵티마이저 정의
loss_fn = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
````model.parameters()`는 모델이 학습해야 할 모든 파라미터(`w`, `b` 등)를 옵티마이저에게 알려주는 역할을 합니다.

---
```

#### **6단계: 학습 루프(Training Loop) 작성**

AI 모델 학습은 정해진 데이터셋을 여러 번 반복해서 보는 과정입니다. 이 반복 과정을 **에포크(epoch)**라고 하며, 전체적인 학습 코드는 이 에포크를 반복하는 `for` 루프로 구성됩니다.

    
```python

# num_epochs: 전체 데이터셋을 몇 번 반복하여 학습할지 결정
num_epochs = 100
# 가상의 입력 데이터와 정답 데이터 생성
inputs = torch.randn(100, 10) # 100개의 샘플, 각 샘플은 10개의 특성
labels = torch.randn(100, 1) # 100개의 정답

for epoch in range(num_epochs):
    # 1. 순전파: 모델을 통해 예측값 계산
    predictions = model(inputs)

    # 2. 손실 계산
    loss = loss_fn(predictions, labels)

    # 3. 역전파를 위한 기울기 초기화
    # 이전 루프의 기울기 값이 누적되므로 매번 0으로 초기화해야 함
    optimizer.zero_grad()

    # 4. 역전파: 손실에 대한 기울기 계산
    loss.backward()

    # 5. 파라미터 업데이트: 계산된 기울기를 바탕으로 가중치 업데이트
    optimizer.step()

    # 일정 주기마다 학습 과정 출력
    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')
```

이 루프가 반복될수록, 모델의 `predictions`는 `labels`에 점점 더 가까워지고 `loss`는 점차 줄어들게 됩니다.

---

#### **7단계: 모델 평가**

학습이 끝난 모델이 새로운 데이터에 대해서도 잘 작동하는지 확인하는 과정입니다. 평가는 학습에 사용되지 않은 별도의 **테스트 데이터셋**으로 수행해야 합니다.

평가 시에는 기울기를 계산할 필요가 없으므로 `torch.no_grad()`를 사용하여 불필요한 연산을 방지하고 메모리를 절약합니다.

```python
# 모델을 평가 모드로 전환
model.eval()

# 평가 시에는 기울기 계산이 필요 없음
with torch.no_grad():
    # 가상의 테스트 데이터
    test_inputs = torch.randn(20, 10)
    test_labels = torch.randn(20, 1)

    test_predictions = model(test_inputs)
    test_loss = loss_fn(test_predictions, test_labels)
    print(f'Test Loss: {test_loss.item():.4f}')

# 다시 학습을 시작하려면 model.train()으로 모드를 변경
model.train()
```

### 언제 Colab Pro (GPU)로 넘어가야 할까요?

지금까지 설명한 모든 과정은 CPU만으로도 충분히 실습하고 이해할 수 있습니다. 다음과 같은 상황이 되면 GPU 사용을 고려할 시점입니다.

1.  **데이터셋이 커질 때**: 수만, 수십만 개 이상의 이미지나 텍스트 데이터를 다룰 때, CPU로는 데이터 로딩과 전처리에 많은 시간이 걸립니다.
2.  **모델이 복잡해질 때**: 이미지 인식을 위한 CNN(Convolutional Neural Network)이나 자연어 처리를 위한 Transformer와 같이 수백만 개 이상의 파라미터를 가진 깊은 모델은 행렬 연산이 매우 많아 GPU의 병렬 처리가 필수적입니다.
3.  **학습 시간이 너무 길어질 때**: 하나의 에포크를 학습하는 데 몇 분 이상 소요되기 시작하면 전체 학습에 수 시간에서 수 일이 걸릴 수 있습니다. 이때 GPU를 사용하면 학습 시간을 획기적으로 단축할 수 있습니다.

---
📌 AI 개발자 3년 로드맵 (정리본)
기간	학습/기술 목표	프로젝트	자격증/성과
### 1년차 (기초 확립)	Python, 자료구조, 수학(선형대수·통계·미적분), 머신러닝 기초, 딥러닝 기본(CNN/RNN), Hugging Face 입문, MLOps 기초	
- 스팸메일 분류기
- 영화 리뷰 감성 분석
- 이미지 분류기(MNIST, CIFAR-10)
- 뉴스 기사 분류기
- 영화 추천 챗봇	
- 🎯 AI 프롬프트 활용능력 (2급)
### 2년차 (중급 심화)	Transformer, BERT, GPT 구조, 파인튜닝(LoRA/PEFT), 멀티모달 AI(OpenCV, YOLOv5), 자율주행 기초(ROS, RL), 음성 AI(Whisper, TTS)	
- 고객센터 QA 챗봇
- CCTV 사람 탐지 AI
- 차선/신호등 인식 자율주행
- 음성으로 특정 인물 찾기	
- 🎯 TensorFlow Developer / AWS ML Specialty
### 3년차 (고급/완성형)	오픈소스 LLM(LLaMA, Mistral) 파인튜닝, RAG, 고급 MLOps(클라우드 배포·GPU 클러스터), 서비스화(UX+API)	
- 내 데이터 기반 GPT (문서 Q&A)
- 기업용 AI 어시스턴트
- 최종 프로젝트(자율주행·음성 AI·코드 생성 AI)	
- 🎯 Kaggle/AI 대회 참여
- 🎯 포트폴리오(GitHub) 완성